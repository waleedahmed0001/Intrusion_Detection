# -*- coding: utf-8 -*-
"""MPLModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X9MOa60c4yzO2iNEqAUAlQ3jQ_-s8Bt-

**Adding Columns Into the dataFrame**
"""

cols="""duration,
protocol_type,
service,
flag,
src_bytes,
dst_bytes,
land,
wrong_fragment,
urgent,
hot,
num_failed_logins,
logged_in,
num_compromised,
root_shell,
su_attempted,
num_root,
num_file_creations,
num_shells,
num_access_files,
num_outbound_cmds,
is_host_login,
is_guest_login,
count,
srv_count,
serror_rate,
srv_serror_rate,
rerror_rate,
srv_rerror_rate,
same_srv_rate,
diff_srv_rate,
srv_diff_host_rate,
dst_host_count,
dst_host_srv_count,
dst_host_same_srv_rate,
dst_host_diff_srv_rate,
dst_host_same_src_port_rate,
dst_host_srv_diff_host_rate,
dst_host_serror_rate,
dst_host_srv_serror_rate,
dst_host_rerror_rate,
dst_host_srv_rerror_rate"""

columns=[]
for c in cols.split(','):
    if(c.strip()):
       columns.append(c.strip())

columns.append('target')
print(columns)
print(len(columns))

attacks_types = {
    'normal': 'normal',
'back': 'dos',
'buffer_overflow': 'u2r',
'ftp_write': 'r2l',
'guess_passwd': 'r2l',
'imap': 'r2l',
'ipsweep': 'probe',
'land': 'dos',
'loadmodule': 'u2r',
'multihop': 'r2l',
'neptune': 'dos',
'nmap': 'probe',
'perl': 'u2r',
'phf': 'r2l',
'pod': 'dos',
'portsweep': 'probe',
'rootkit': 'u2r',
'satan': 'probe',
'smurf': 'dos',
'spy': 'r2l',
'teardrop': 'dos',
'warezclient': 'r2l',
'warezmaster': 'r2l',
}

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
data=pd.read_csv('/content/drive/MyDrive/kddcup.csv.data',names=columns)
data['Attack Type'] = data.target.apply(lambda r:attacks_types[r[:-1]])
data.head()

# data.shape
# import matplotlib.pyplot as plt
# x=range(0,len(data))
# import seaborn as sns


# plt.figure(figsize=(12,10))
# plt.plot(x,data['Attack Type'])""
# plt.scatter(x,data['Attack Type'])

# plt.plot()
data.head(10)

data['Attack Type'].value_counts()

# Exploratory data analysis
import matplotlib.pyplot as plt
from matplotlib.pyplot import *

plt.figure(figsize=(15,7))
class_distribution = data['Attack Type'].value_counts()
class_distribution.plot(kind='bar')
plt.xlabel('Class')
plt.ylabel('Data points per Class')
plt.title('Distribution of yi in train data')
plt.grid()
plt.show()

data=data.drop(['target'],axis=1)
data.drop_duplicates(keep='first', inplace = True)

data.shape

# data['protocol_type']=pd.factorize(data.protocol_type)[0]
# data['service']=pd.factorize(data.service)[0]
# data['flag']=pd.factorize(data.flag)[0]
# data['Attack Type']=pd.factorize(data['Attack Type'])[0]

def mappData(column):
  lable=0
  resultDict={}
  for item in data[column].unique():
    data[column]=data[column].replace([item],[lable])
    resultDict[lable]=item
    lable+=1
  return resultDict

protocol_type_map=mappData("protocol_type")
print(protocol_type_map)

service_map=mappData("service")
print(service_map)

flag_map=mappData("flag")
print(flag_map)

Attack_Type_map=mappData("Attack Type")
print(Attack_Type_map)

data.shape

Y=data['Attack Type']

data=data.drop(['Attack Type'],axis=1)



print(Y)

# Y.unique()
data.head(10)

from sklearn.preprocessing import StandardScaler
Scaler= StandardScaler()
# for col in data:
#   # data[col].fillna(data[col].mean(),inplace=True)
#   data[col]=Scaler.fit_transform(data[col].values.reshape(-1,1))
data = Scaler.fit_transform(data)

# data[1]
Scaler

import numpy as np
unique, counts = np.unique(Y, return_counts=True)
np.asarray((unique, counts)).T

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(data, Y, test_size=0.04,stratify=Y)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

from sklearn.neural_network import MLPClassifier
#  three hidden layers as default
mlp=MLPClassifier(activation='relu',max_iter=8)
mlp.fit(X_train,y_train)

get=mlp.predict(X_test)

len(get)

y_test=list(y_test)

# (get == y_test).sum() 
(get == y_test).sum() / y_test.shape[0]

(get == y_test).sum() / len(y_test)

print(get)
print(len(get))

# y_test.shape()



from sklearn.metrics import confusion_matrix
cf_matrix = confusion_matrix(get,y_test)

print(cf_matrix)

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12,10))
ax = sns.heatmap(cf_matrix, annot=False, cmap='Blues')

ax.set_title('Seaborn Confusion Matrix with labels\n\n');
ax.set_xlabel('\nPredicted Values')
ax.set_ylabel('Actual Values ');

## Ticket labels - List must be in alphabetical order
# ax.xaxis.set_ticklabels(['False','True'])
# ax.yaxis.set_ticklabels(['False','True'])

## Display the visualization of the Confusion Matrix.
plt.show()

plt.figure(figsize=(15,15))
# plt.scatter(X_train, y_train, color = 'red')
plt.plot(X_test, get, color = 'blue')
plt.show()
# plt.scatter(y_test, get, c='crimson')
# plt.yscale('log')
# plt.xscale('log')

# p1 = max(max(get), max(y_test))
# p2 = min(min(get), min(y_test))
# plt.plot([p1, p2], [p1, p2], 'b-')
# plt.xlabel('True Values', fontsize=15)
# plt.ylabel('Predictions', fontsize=15)
# plt.axis('equal')
# plt.show()

plt.figure(figsize=(15,15))
g=plt.plot(y_test - get,marker='o',linestyle='')

import pickle
pickle.dump(mlp, open('mlpmodel.pkl', 'wb'))

"""## RNN MODEL"""

import numpy as np
X_train1=np.array(X_train)
y_train1=np.array(y_train)
y_train=list(y_train)
X_train1=np.reshape(X_train1,(X_train1.shape[0],X_train1.shape[1],1))

from tensorflow import keras
from tensorflow.keras import layers
from keras.layers import Dense,LSTM,Dropout
from tensorflow.keras.callbacks import EarlyStopping

RNNmodel = keras.Sequential()

RNNmodel.add(LSTM(units=50,return_sequences=True, input_shape=(X_train1.shape[1],1)))
RNNmodel.add(Dropout(0.2))

RNNmodel.add(LSTM(units=50,return_sequences=True))
RNNmodel.add(Dropout(0.2))

RNNmodel.add(LSTM(units=50))
RNNmodel.add(Dropout(0.2))

RNNmodel.add(Dense(units=1))

RNNmodel.add(Dense(1,activation='sigmoid'))

RNNmodel.compile(
    optimizer="adam",loss='categorical_crossentropy'
)

RNNmodel.summary()

RNNmodel.fit(X_train1,y_train1,epochs=1,batch_size=32)



import pickle
pickle.dump(RNNmodel, open('/content/RNNmodel.pkl', 'wb'))

score = RNNmodel.evaluate(X_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# model = keras.Sequential()
# model.add(Dense(512, activation='relu', input_shape=(X_train1.shape[1],1)))
# model.add(Dropout(0.5))
# model.add(Dense(256, activation='relu'))
# model.add(Dropout(0.25))
# model.add(Dense(100, activation='softmax'))
# model.add(Dropout(0.1))
# import livelossplot
# plot_losses = livelossplot.PlotLossesKeras()

# Compile model
# model.compile(optimizer='rmsprop',
#               loss='categorical_crossentropy',
#               metrics=['accuracy'])
# from tensorflow import keras
# from tensorflow.keras import layers
# from keras.layers import Dense,LSTM,Dropout
# model = keras.Sequential()
    
# model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))
# # model.add(BatchNormalization())
# # model.add(MaxPooling2D(pool_size=(3, 3)))
# # model.add(Flatten())
# model.add(Dense(512, activation='relu'))
# model.add(Dense(1,activation='softmax'))

# model.compile(optimizer='adam',
#               loss='categorical_crossentropy',
#               metrics=['accuracy'])

# Train model
# model.fit(X_train1, y_train1,
#           epochs=2,
#           batch_size=32
#           )

# score = model.evaluate(X_test, y_test, verbose=0)
# print('Test loss:', score[0])
# print('Test accuracy:', score[1])
import pickle
mlp = pickle.load(open('/content/mlpmodel.pkl', 'rb'))
# pickled_model.predict(X_test)

score = pickled_model.evaluate(X_test, y_test, verbose=0)
# print('Test loss:', score[0])
# print('Test accuracy:', score[1])

score

print(score)

get=pickled_model.predict(X_test)

# import pickle
# dict1 = {'hello' : 1, 'brother' : 2}
file1 = open("rnnpredict.txt", "wb") 
pickle.dump(get, file1)
file1.close
file2 = open("y_test.txt", "wb") 
pickle.dump(y_test,file2)
file2.close()

get

import numpy as np
y_test=np.array(y_test)



len(get)

type(y_test)

y_test=list(y_test)

len(y_test)
get=list(get)

count=0
for i,j in range(y_test):
  if (y_test[i]==get[i]):
    count+=1

count

get=np.array(get)

y_test=np.array(y_test)

y_test.ndim

get=get.reshape(y_test.shape)

(get==y_test).sum()/len(y_test)

get

y_test

get= pd.factorize(data['Attack Type'])

import requests
import numpy as np
import os
from sklearn.model_selection import train_test_split
from sklearn import metrics
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation
from tensorflow.keras.callbacks import EarlyStopping



# Create neural net
model = Sequential()
model.add(Dense(X_train.shape[1], input_dim=data.shape[1], kernel_initializer='normal', activation='relu'))
model.add(Dense(70, input_dim=data.shape[1], kernel_initializer='normal', activation='relu'))
model.add(Dense(35, input_dim=data.shape[1], kernel_initializer='normal', activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))
model.add(Dense(1,activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam')
monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')
model.fit(X_train,y_train,validation_data=(X_test,y_test),callbacks=[monitor],verbose=2,epochs=10)

import tensorflow.keras.backend as K
print('Learning Rate - ')
print(K.eval(model.optimizer.lr)) 
print('='*50)
model.summary()

# get=model.predict(X_test)
(get == y_test).sum() / len(y_test)

import seaborn as sns
import datetime as dt

def confusion_matrix_func(y_test, y_test_pred):
    
    '''
    This function computes the confusion matrix using Predicted and Actual values and plots a confusion matrix heatmap
    '''
    C = confusion_matrix(y_test, y_test_pred)
    cm_df = pd.DataFrame(C)
    labels = ['back', 'butter_overflow', 'loadmodule', 'guess_passwd', 'imap', 'ipsweep', 'warezmaster', 'rootkit', 
'multihop', 'neptune', 'nmap', 'normal', 'phf', 'perl', 'pod', 'portsweep', 'ftp_write', 'satan', 'smurf', 'teardrop', 'warezclient', 'land']
    plt.figure(figsize=(20,15))
    sns.set(font_scale=1.4)
    sns.heatmap(cm_df, annot=True, annot_kws={"size":12}, fmt='g', xticklabels=labels, yticklabels=labels)
    plt.ylabel('Actual Class')
    plt.xlabel('Predicted Class')
    
    plt.show()

# calculate roc curve
from sklearn.metrics import *
#fpr_RF, tpr_RF, thresholds_RF = roc_curve(y_test, pred)
from sklearn import preprocessing
def multiclass_roc_auc_score(y_test, pred, average="macro"):
    lb = preprocessing.LabelBinarizer()
    lb.fit(y_test)
    y_test = lb.transform(y_test)
    pred = lb.transform(pred)
    return roc_auc_score(y_test, pred, average=average)



print('Train data')
print(X_train.shape)
print(y_train.shape)
print('='*20)
print('Test data')
print(X_test.shape)
print(y_test.shape)
print('='*20)

# Measure accuracy
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score
print('Predicting on the test data:')
start = dt.datetime.now()
escore = model.evaluate(X_test, y_test, batch_size=32)
pred = model.predict(X_test)
pred = np.argmax(pred,axis=1)
y_eval = np.argmax(y_test,axis=1)

vscore = metrics.accuracy_score(y_eval, pred)

rscore = recall_score(y_eval, pred, average='weighted')

ascore = precision_score(y_eval, pred, average='weighted')

f1score= f1_score(y_eval, pred, average='weighted') #F1 = 2 * (precision * recall) / (precision + recall) for manual

roc_auc_socre = multiclass_roc_auc_score(y_eval, pred)



print('Completed')
print('Time taken:',dt.datetime.now()-start)
print('='*50)
print("Validation score: {}".format(vscore))
print('='*50)
print("Evaluation score: {}".format(escore))
print('='*50)
print("Recall score: {}".format(rscore))
print('='*50)
print("Precision score: {}".format(ascore))
print('='*50)
print("F1 score: {}".format(f1score))
print('='*50)
print("ROC-AUC score: {}".format(roc_auc_socre))

def preprocessing(value):
  x = value.split(",")
  for i in range(len(x)): 
    # print(x[i]) 
    x[i]=x[i].strip()
  print(type(x))

  return x

x=preprocessing("0,icmp,ecr_i,SF,1032,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,511,511,0.00,0.00,0.00,0.00,1.00,0.00,0.00,255,255,1.00,0.00,1.00,0.00,0.00,0.00,0.00,0.00")

# new_arr=np.array(x)

# x[1]
print(protocol_type_map)

x[1]=list(protocol_type_map.keys())[list(protocol_type_map.values()).index(x[1])]

x[2]=list(service_map.keys())[list(service_map.values()).index(x[2])]

x[3]=list(flag_map.keys())[list(flag_map.values()).index(x[3])]

data=data.drop(['Attack Type'],axis=1)

import numpy as np
rows, cols = (1, 41)
 
# method 2a
arr = [cols]*rows
arr[0]=x
# B = np.reshape(x, (-1, 2))
checking=Scaler.transform(arr)

checking

df_length = len(data)
data.loc[df_length] = x

data.shape

from sklearn.preprocessing import StandardScaler
Scaler= StandardScaler()
for col in data:
  # data[col].fillna(data[col].mean(),inplace=True)
  data[col]=Scaler.fit_transform(data[col].values.reshape(-1,1))

last_column = data.tail(1)

last_column

type(last_column)

ans=model.predict(last_column)

ans

ans=ans[0]
ans

final_answer=list(Attack_Type_map.values())[list(Attack_Type_map.keys()).index(ans)]

final_answer

last_row = len(data)
data = data.drop(data.index[last_row-1])

data.shape

print(Scaler)

import pickle
pickle.dump(Scaler, open('scaler.pkl', 'wb'))

import pickle
mlp = pickle.load(open('/content/updatedmlpmodel.pkl', 'rb'))

mlp.summary()

get=mlp.predict(X_test)

newdf = pd.DataFrame()

ls=range(0,len(y_test))

# newdf.shape
# get.ndim

newdf['get']=get

newdf['index']=ls

# import pandas as pd
newdf['y_test']=y_test
newdf.head

# newdf.plot(x="index", y="y_test")



